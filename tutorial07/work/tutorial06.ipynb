{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02d2b421-b3cc-4440-b0c7-654039057708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/site-packages (19.0.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (2025.3.2)\n",
      "Requirement already satisfied: s3fs in /usr/local/lib/python3.11/site-packages (2025.3.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in /usr/local/lib/python3.11/site-packages (from s3fs) (2.21.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/site-packages (from s3fs) (3.11.18)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (0.12.0)\n",
      "Requirement already satisfied: botocore<1.37.2,>=1.37.0 in /usr/local/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.37.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.0.1)\n",
      "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /usr/local/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (6.4.3)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.6.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/site-packages (from botocore<1.37.2,>=1.37.0->aiobotocore<3.0.0,>=2.5.4->s3fs) (2.2.2)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas pyarrow fsspec s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72d7818c-7931-4e06-a76c-6b90abd7a62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# API endpoint and parameters\n",
    "WEATHER_ENDPOINT = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "API_KEY = \"70e208d9d8ba1534136297fb1f3fe396\"  # Replace with your actual API key\n",
    "\n",
    "\n",
    "locations = {\n",
    "    \"Satitram Alumni\": {\"lat\": 13.754174, \"lon\": 100.615676},\n",
    "}\n",
    "\n",
    "def get_weather_data(location_name='Satitram Alumni'):\n",
    "    lat = locations[location_name]['lat']\n",
    "    lon = locations[location_name]['lon']\n",
    "\n",
    "    params = {\n",
    "        \"lat\": lat,\n",
    "        \"lon\": lon,\n",
    "        \"appid\": API_KEY,\n",
    "        \"units\": \"metric\",\n",
    "        \"lang\": \"th\"\n",
    "    }\n",
    "    try:\n",
    "        # Make API request\n",
    "        response = requests.get(WEATHER_ENDPOINT, params=params)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        data = response.json()\n",
    "        \n",
    "        # Convert timestamp to datetime\n",
    "        # created_at = datetime.fromtimestamp(data['dt'])\n",
    "\n",
    "        dt = datetime.now()\n",
    "        thai_tz = pytz.timezone('Asia/Bangkok')\n",
    "        created_at = dt.replace(tzinfo=thai_tz)\n",
    "\n",
    "\n",
    "        timestamp = datetime.now()\n",
    "        \n",
    "        # Create dictionary with required fields\n",
    "        weather_dict = {\n",
    "            'timestamp': timestamp,\n",
    "            'year': timestamp.year,\n",
    "            'month': timestamp.month,\n",
    "            'day': timestamp.day,\n",
    "            'hour': timestamp.hour,\n",
    "            'minute': timestamp.minute,\n",
    "            'created_at': created_at,\n",
    "            'location': location_name,\n",
    "            'temperature': data['main']['temp'],\n",
    "            'feels_like': data['main']['feels_like'],\n",
    "            'humidity': data['main']['humidity'],\n",
    "            'pressure': data['main']['pressure'],\n",
    "            'wind_speed': data['wind']['speed'],\n",
    "            'visibility': data.get('visibility'),\n",
    "            'weather_main': data['weather'][0]['main'],\n",
    "            'weather_description': data['weather'][0]['description']\n",
    "        }\n",
    "        \n",
    "        # Create DataFrame\n",
    "        # df = pd.DataFrame([weather_dict])\n",
    "        \n",
    "        # return df\n",
    "        return weather_dict\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None\n",
    "    except KeyError as e:\n",
    "        print(f\"Error processing data: Missing key {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19fa0be2-9d17-46a7-9065-4507629fd910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype                       \n",
      "---  ------               --------------  -----                       \n",
      " 0   timestamp            1 non-null      datetime64[ns]              \n",
      " 1   year                 1 non-null      int64                       \n",
      " 2   month                1 non-null      int64                       \n",
      " 3   day                  1 non-null      int64                       \n",
      " 4   hour                 1 non-null      int64                       \n",
      " 5   minute               1 non-null      int64                       \n",
      " 6   created_at           1 non-null      datetime64[ns, Asia/Bangkok]\n",
      " 7   location             1 non-null      object                      \n",
      " 8   temperature          1 non-null      float64                     \n",
      " 9   feels_like           1 non-null      float64                     \n",
      " 10  humidity             1 non-null      int64                       \n",
      " 11  pressure             1 non-null      int64                       \n",
      " 12  wind_speed           1 non-null      float64                     \n",
      " 13  visibility           1 non-null      int64                       \n",
      " 14  weather_main         1 non-null      object                      \n",
      " 15  weather_description  1 non-null      object                      \n",
      "dtypes: datetime64[ns, Asia/Bangkok](1), datetime64[ns](1), float64(3), int64(8), object(3)\n",
      "memory usage: 260.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>created_at</th>\n",
       "      <th>location</th>\n",
       "      <th>temperature</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>visibility</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-09 09:01:29.866781</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-05-09 09:19:29.866494+07:00</td>\n",
       "      <td>Satitram Alumni</td>\n",
       "      <td>35.3</td>\n",
       "      <td>42.3</td>\n",
       "      <td>58</td>\n",
       "      <td>1003</td>\n",
       "      <td>4.12</td>\n",
       "      <td>10000</td>\n",
       "      <td>Thunderstorm</td>\n",
       "      <td>พายุฟ้าคะนอง</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp  year  month  day  hour  minute  \\\n",
       "0 2025-05-09 09:01:29.866781  2025      5    9     9       1   \n",
       "\n",
       "                        created_at         location  temperature  feels_like  \\\n",
       "0 2025-05-09 09:19:29.866494+07:00  Satitram Alumni         35.3        42.3   \n",
       "\n",
       "   humidity  pressure  wind_speed  visibility  weather_main  \\\n",
       "0        58      1003        4.12       10000  Thunderstorm   \n",
       "\n",
       "  weather_description  \n",
       "0        พายุฟ้าคะนอง  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame([get_weather_data(p) for p in list(locations.keys())])\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bdd175b-f75b-43d7-92ef-2a83237e3669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 08:43:12.246090+06:42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dt = datetime.now()\n",
    "thai_tz = pytz.timezone('Asia/Bangkok')\n",
    "dt = dt.replace(tzinfo=thai_tz)\n",
    "print(dt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56f77c2b-a1be-46c4-9537-cd7aca2c0323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# lakeFS credentials from your docker-compose.yml\n",
    "ACCESS_KEY = \"access_key\"\n",
    "SECRET_KEY = \"secret_key\"\n",
    "\n",
    "# lakeFS endpoint (running locally)\n",
    "lakefs_endpoint = \"http://lakefs-dev:8000/\"\n",
    "\n",
    "# lakeFS repository, branch, and file path\n",
    "repo = \"weather\"\n",
    "branch = \"main\"\n",
    "path = \"weather.parquet\"\n",
    "\n",
    "# Construct the full lakeFS S3-compatible path\n",
    "lakefs_s3_path = f\"s3a://{repo}/{branch}/{path}\"\n",
    "\n",
    "# Configure storage_options for lakeFS (S3-compatible)\n",
    "storage_options = {\n",
    "    \"key\": ACCESS_KEY,\n",
    "    \"secret\": SECRET_KEY,\n",
    "    \"client_kwargs\": {\n",
    "        \"endpoint_url\": lakefs_endpoint\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd9052d7-5834-4242-8fb5-2df9ed4b4ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\n",
    "    lakefs_s3_path,\n",
    "    storage_options=storage_options,\n",
    "    partition_cols=['year','month','day','hour'],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4545df5e-b3f6-4c46-a196-7334bb0af669",
   "metadata": {},
   "source": [
    "# test read parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc5a8f92-3be2-44bd-809c-1e726292c5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (2025.3.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d01ca533-521a-443f-b0fe-1dc357314e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather/main/weather.parquet/year=2025']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.ls(\"s3a://weather/main/weather.parquet/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "277e9ec9-7fcf-4ca3-8516-eada4a5303b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather/main/weather.parquet/year=2025/month=5']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.ls(\"s3a://weather/main/weather.parquet/year=2025/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17234632-1876-43aa-bf80-fc5bdb9fb9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather/main/weather.parquet/year=2025/month=5/day=8/hour=6/439dca34b97444a38671facd7d64e596-0.parquet',\n",
       " 'weather/main/weather.parquet/year=2025/month=5/day=8/hour=6/5843a0197e6f4d3385f0c27edc89b412-0.parquet',\n",
       " 'weather/main/weather.parquet/year=2025/month=5/day=8/hour=6/96d8715177f747f78b6bc8209d5b4109-0.parquet',\n",
       " 'weather/main/weather.parquet/year=2025/month=5/day=8/hour=6/d99fcd42f2fd410dbacae4f65539620a-0.parquet',\n",
       " 'weather/main/weather.parquet/year=2025/month=5/day=8/hour=6/fa7200c1242c4859bd91000325b41611-0.parquet']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.ls(\"s3a://weather/main/weather.parquet/year=2025/month=5/day=8/\")\n",
    "fs.ls(\"s3a://weather/main/weather.parquet/year=2025/month=5/day=8/hour=6/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aaa585f3-5e39-48a3-99dc-cf09794b3aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ค้นหาพาธที่มีไฟล์จริงทั้งหมด\n",
    "parquet_paths = fs.glob(\"weather/main/weather.parquet/year=*/month=*/day=*/hour=*/*.parquet\")\n",
    "\n",
    "# โหลดแต่ไฟล์ที่มีอยู่จริง\n",
    "dfs = [pd.read_parquet(f\"s3a://{path}\", storage_options=storage_options) for path in parquet_paths]\n",
    "df2 = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb302fc4-f4ff-4454-87c2-7616f422546f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files (0):\n"
     ]
    }
   ],
   "source": [
    "paths = fs.glob(\"weather/main/weather.parquet/year=*/month=*/day=*/hour=*/*.parquet\")\n",
    "missing = [p for p in paths if not fs.isfile(p)]\n",
    "\n",
    "print(f\"Missing files ({len(missing)}):\")\n",
    "for m in missing:\n",
    "    print(\"-\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9703e66e-ea17-47cf-9067-4cca2fa8c2b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "weather/main/weather.parquet/year=2025/month=5/day=8/hour=6/dd1741ec35434825a62561e9625ed3e8-0.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m path_all_partition = \u001b[33m'\u001b[39m\u001b[33ms3a://weather/main/weather.parquet\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df2=\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m    \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_all_partition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m df2.info()\n\u001b[32m      8\u001b[39m df2.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pandas/io/parquet.py:667\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    664\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    665\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pandas/io/parquet.py:274\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    267\u001b[39m path_or_handle, handles, filesystem = _get_path_or_handle(\n\u001b[32m    268\u001b[39m     path,\n\u001b[32m    269\u001b[39m     filesystem,\n\u001b[32m    270\u001b[39m     storage_options=storage_options,\n\u001b[32m    271\u001b[39m     mode=\u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    272\u001b[39m )\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m     pa_table = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparquet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    281\u001b[39m     result = pa_table.to_pandas(**to_pandas_kwargs)\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pyarrow/parquet/core.py:1843\u001b[39m, in \u001b[36mread_table\u001b[39m\u001b[34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[39m\n\u001b[32m   1831\u001b[39m     \u001b[38;5;66;03m# TODO test that source is not a directory or a list\u001b[39;00m\n\u001b[32m   1832\u001b[39m     dataset = ParquetFile(\n\u001b[32m   1833\u001b[39m         source, read_dictionary=read_dictionary,\n\u001b[32m   1834\u001b[39m         memory_map=memory_map, buffer_size=buffer_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1840\u001b[39m         page_checksum_verification=page_checksum_verification,\n\u001b[32m   1841\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1844\u001b[39m \u001b[43m                    \u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pyarrow/parquet/core.py:1485\u001b[39m, in \u001b[36mParquetDataset.read\u001b[39m\u001b[34m(self, columns, use_threads, use_pandas_metadata)\u001b[39m\n\u001b[32m   1477\u001b[39m         index_columns = [\n\u001b[32m   1478\u001b[39m             col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m _get_pandas_index_columns(metadata)\n\u001b[32m   1479\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m   1480\u001b[39m         ]\n\u001b[32m   1481\u001b[39m         columns = (\n\u001b[32m   1482\u001b[39m             \u001b[38;5;28mlist\u001b[39m(columns) + \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(index_columns) - \u001b[38;5;28mset\u001b[39m(columns))\n\u001b[32m   1483\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1485\u001b[39m table = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1486\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_filter_expression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1487\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_threads\u001b[49m\n\u001b[32m   1488\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1490\u001b[39m \u001b[38;5;66;03m# if use_pandas_metadata, restore the pandas metadata (which gets\u001b[39;00m\n\u001b[32m   1491\u001b[39m \u001b[38;5;66;03m# lost if doing a specific `columns` selection in to_table)\u001b[39;00m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_pandas_metadata:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pyarrow/_dataset.pyx:574\u001b[39m, in \u001b[36mpyarrow._dataset.Dataset.to_table\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pyarrow/_dataset.pyx:3865\u001b[39m, in \u001b[36mpyarrow._dataset.Scanner.to_table\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pyarrow/error.pxi:155\u001b[39m, in \u001b[36mpyarrow.lib.pyarrow_internal_check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pyarrow/error.pxi:89\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pyarrow/_fs.pyx:1559\u001b[39m, in \u001b[36mpyarrow._fs._cb_open_input_file\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pyarrow/fs.py:419\u001b[39m, in \u001b[36mFSSpecHandler.open_input_file\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PythonFile\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fs.isfile(path):\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(path)\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m PythonFile(\u001b[38;5;28mself\u001b[39m.fs.open(path, mode=\u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m), mode=\u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: weather/main/weather.parquet/year=2025/month=5/day=8/hour=6/dd1741ec35434825a62561e9625ed3e8-0.parquet"
     ]
    }
   ],
   "source": [
    "path_all_partition = 's3a://weather/main/weather.parquet'\n",
    "\n",
    "df2=pd.read_parquet(    \n",
    "    path=path_all_partition,\n",
    "    storage_options=storage_options\n",
    ")\n",
    "df2.info()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b483f8da-bc2a-4147-8684-4c5310a0472e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype                       \n",
      "---  ------               --------------  -----                       \n",
      " 0   timestamp            4 non-null      datetime64[ns]              \n",
      " 1   minute               4 non-null      int64                       \n",
      " 2   created_at           4 non-null      datetime64[ns, Asia/Bangkok]\n",
      " 3   requested_province   4 non-null      object                      \n",
      " 4   location             4 non-null      object                      \n",
      " 5   weather_main         4 non-null      object                      \n",
      " 6   weather_description  4 non-null      object                      \n",
      " 7   main.temp            4 non-null      float64                     \n",
      " 8   year                 4 non-null      category                    \n",
      " 9   month                4 non-null      category                    \n",
      " 10  day                  4 non-null      category                    \n",
      " 11  hour                 4 non-null      category                    \n",
      "dtypes: category(4), datetime64[ns, Asia/Bangkok](1), datetime64[ns](1), float64(1), int64(1), object(4)\n",
      "memory usage: 788.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>minute</th>\n",
       "      <th>created_at</th>\n",
       "      <th>requested_province</th>\n",
       "      <th>location</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>main.temp</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-01 11:31:10.350466</td>\n",
       "      <td>31</td>\n",
       "      <td>2025-05-01 11:49:10.333970+07:00</td>\n",
       "      <td>Pathum Thani</td>\n",
       "      <td>Pathum Thani</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>33.15</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-01 11:31:10.717529</td>\n",
       "      <td>31</td>\n",
       "      <td>2025-05-01 11:49:10.717493+07:00</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>33.94</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-01 11:31:11.057869</td>\n",
       "      <td>31</td>\n",
       "      <td>2025-05-01 11:49:11.057842+07:00</td>\n",
       "      <td>Chiang Mai</td>\n",
       "      <td>Chiang Mai</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>31.28</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-01 11:31:11.341738</td>\n",
       "      <td>31</td>\n",
       "      <td>2025-05-01 11:49:11.341696+07:00</td>\n",
       "      <td>Phuket</td>\n",
       "      <td>Kathu</td>\n",
       "      <td>Rain</td>\n",
       "      <td>moderate rain</td>\n",
       "      <td>25.92</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp  minute                       created_at  \\\n",
       "0 2025-05-01 11:31:10.350466      31 2025-05-01 11:49:10.333970+07:00   \n",
       "1 2025-05-01 11:31:10.717529      31 2025-05-01 11:49:10.717493+07:00   \n",
       "2 2025-05-01 11:31:11.057869      31 2025-05-01 11:49:11.057842+07:00   \n",
       "3 2025-05-01 11:31:11.341738      31 2025-05-01 11:49:11.341696+07:00   \n",
       "\n",
       "  requested_province      location weather_main weather_description  \\\n",
       "0       Pathum Thani  Pathum Thani       Clouds          few clouds   \n",
       "1            Bangkok       Bangkok       Clouds     overcast clouds   \n",
       "2         Chiang Mai    Chiang Mai       Clouds          few clouds   \n",
       "3             Phuket         Kathu         Rain       moderate rain   \n",
       "\n",
       "   main.temp  year month day hour  \n",
       "0      33.15  2025     5   1   11  \n",
       "1      33.94  2025     5   1   11  \n",
       "2      31.28  2025     5   1   11  \n",
       "3      25.92  2025     5   1   11  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_single_partition = 's3a://weather/main/weather.parquet/year=2025/month=5/day=1/hour=11/8aeb52f0592d41f08e38c309edb03084-0.parquet'\n",
    "\n",
    "df2=pd.read_parquet(    \n",
    "    path=path_single_partition,\n",
    "    storage_options=storage_options,\n",
    ")\n",
    "df2.info()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6909c16e-e300-40b2-b9b0-2c9ecad69c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-08 06:57:17.495138+06:42\n"
     ]
    }
   ],
   "source": [
    "print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d82d9f-46e6-4148-aa59-c402867f7529",
   "metadata": {},
   "source": [
    "# Test Duck and Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0392960c-a68b-4b92-8981-0379fd93b7b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "IOException",
     "evalue": "IO Error: Could not establish connection error for HTTP HEAD to 'http://localhost:8001/weather/main/weather.parquet' with status -80068480",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIOException\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Use DuckDB's read_parquet() function to read the dataset.\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Assume the dataset is stored in the directory \"output_parquet_dataset\" with hive partitions:\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# output_parquet_dataset/year=2025/month=02/day=17/...\u001b[39;00m\n\u001b[32m     19\u001b[39m query = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[33mINSTALL httpfs;\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[33mLOAD httpfs;\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \u001b[33mFROM read_parquet(\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms3://weather/main/weather.parquet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m);\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m df_duck = \u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m.df()\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDuckDB Parquet Query Result:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m df_duck.info()\n",
      "\u001b[31mIOException\u001b[39m: IO Error: Could not establish connection error for HTTP HEAD to 'http://localhost:8001/weather/main/weather.parquet' with status -80068480"
     ]
    }
   ],
   "source": [
    "# !pip install duckdb\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to an in-memory DuckDB instance.\n",
    "con = duckdb.connect(database=':memory:')\n",
    "\n",
    "storage_options = {\n",
    "    \"key\": ACCESS_KEY,\n",
    "    \"secret\": SECRET_KEY,\n",
    "    \"client_kwargs\": {\n",
    "        \"endpoint_url\": lakefs_endpoint\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use DuckDB's read_parquet() function to read the dataset.\n",
    "# Assume the dataset is stored in the directory \"output_parquet_dataset\" with hive partitions:\n",
    "# output_parquet_dataset/year=2025/month=02/day=17/...\n",
    "query = \"\"\"\n",
    "INSTALL httpfs;\n",
    "LOAD httpfs;\n",
    "\n",
    "SET s3_endpoint='localhost:8001';\n",
    "SET s3_access_key_id='access_key'; \n",
    "SET s3_secret_access_key='secret_key'; \n",
    "SET s3_url_style='path';\n",
    "SET s3_use_ssl=false;\n",
    "\n",
    "SELECT *\n",
    "FROM read_parquet('s3://weather/main/weather.parquet');\n",
    "\"\"\"\n",
    "\n",
    "df_duck = con.execute(query).df()\n",
    "\n",
    "print(\"DuckDB Parquet Query Result:\")\n",
    "df_duck.info()\n",
    "df_duck.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3c6a0fe-a4e2-40bc-96bc-e72445f8a352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask in /usr/local/lib/python3.11/site-packages (2025.4.1)\n",
      "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/site-packages (from dask) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/site-packages (from dask) (3.0.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/site-packages (from dask) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from dask) (24.1)\n",
      "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/site-packages (from dask) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/site-packages (from dask) (6.0.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/site-packages (from dask) (1.0.0)\n",
      "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/site-packages (from dask) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/site-packages (from importlib_metadata>=4.13.0->dask) (3.21.0)\n",
      "Requirement already satisfied: locket in /usr/local/lib/python3.11/site-packages (from partd>=1.4.0->dask) (1.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61675751-f080-4129-8885-cecac2d6d786",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "An error occurred while calling the read_parquet method registered to the pandas backend.\nOriginal Message: weather/main/weather.parquet/year=2025/month=5/day=8/hour=6/dd1741ec35434825a62561e9625ed3e8-0.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/dask/backends.py:140\u001b[39m, in \u001b[36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/dask/dataframe/dask_expr/_collection.py:5372\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, columns, filters, categories, index, storage_options, dtype_backend, calculate_divisions, ignore_metadata_file, metadata_task_size, split_row_groups, blocksize, aggregate_files, parquet_file_extension, filesystem, engine, arrow_to_pandas, **kwargs)\u001b[39m\n\u001b[32m   5353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m new_collection(\n\u001b[32m   5354\u001b[39m         ReadParquetPyarrowFS(\n\u001b[32m   5355\u001b[39m             path,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5368\u001b[39m         )\n\u001b[32m   5369\u001b[39m     )\n\u001b[32m   5371\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_collection(\n\u001b[32m-> \u001b[39m\u001b[32m5372\u001b[39m     \u001b[43mReadParquetFSSpec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5373\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5374\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_convert_to_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5377\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5378\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcalculate_divisions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcalculate_divisions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_metadata_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_metadata_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata_task_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata_task_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5382\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_row_groups\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_row_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5383\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5384\u001b[39m \u001b[43m        \u001b[49m\u001b[43maggregate_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43maggregate_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5385\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparquet_file_extension\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparquet_file_extension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_set_parquet_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5389\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_series\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5390\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5391\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/dask/_expr.py:844\u001b[39m, in \u001b[36mSingletonExpr.__new__\u001b[39m\u001b[34m(cls, _determ_token, *args, **kwargs)\u001b[39m\n\u001b[32m    843\u001b[39m     \u001b[38;5;28mcls\u001b[39m._instances = weakref.WeakValueDictionary()\n\u001b[32m--> \u001b[39m\u001b[32m844\u001b[39m inst = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__new__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_determ_token\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_determ_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    845\u001b[39m _name = inst._name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/dask/_expr.py:72\u001b[39m, in \u001b[36mExpr.__new__\u001b[39m\u001b[34m(cls, _determ_token, *args, **kwargs)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# This is typically cached. Make sure the cache is populated by calling\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# it once\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m \u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_name\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inst\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/functools.py:1001\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, instance, owner)\u001b[39m\n\u001b[32m   1000\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m     val = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1002\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/dask/dataframe/dask_expr/io/parquet.py:790\u001b[39m, in \u001b[36mReadParquet._name\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[32m    789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_name\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._funcname + \u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdeterministic_token\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/dask/_expr.py:517\u001b[39m, in \u001b[36mExpr.deterministic_token\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    514\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._determ_token:\n\u001b[32m    515\u001b[39m     \u001b[38;5;66;03m# Just tokenize self to fall back on __dask_tokenize__\u001b[39;00m\n\u001b[32m    516\u001b[39m     \u001b[38;5;66;03m# Note how this differs to the implementation of __dask_tokenize__\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     \u001b[38;5;28mself\u001b[39m._determ_token = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__dask_tokenize__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._determ_token\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/dask/dataframe/dask_expr/io/parquet.py:784\u001b[39m, in \u001b[36mReadParquet.__dask_tokenize__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._determ_token:\n\u001b[32m    782\u001b[39m     \u001b[38;5;66;03m# TODO: Is there an actual need to overwrite this?\u001b[39;00m\n\u001b[32m    783\u001b[39m     \u001b[38;5;28mself\u001b[39m._determ_token = _tokenize_deterministic(\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m         funcname(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)), \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchecksum\u001b[49m, *\u001b[38;5;28mself\u001b[39m.operands[:-\u001b[32m1\u001b[39m]\n\u001b[32m    785\u001b[39m     )\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._determ_token\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/dask/dataframe/dask_expr/io/parquet.py:794\u001b[39m, in \u001b[36mReadParquet.checksum\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    792\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    793\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mchecksum\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_info\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mchecksum\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/dask/dataframe/dask_expr/io/parquet.py:1394\u001b[39m, in \u001b[36mReadParquetFSSpec._dataset_info\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1390\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files_for_checksum:\n\u001b[32m   1391\u001b[39m     \u001b[38;5;66;03m# The checksum / file info is usually already cached by the fsspec\u001b[39;00m\n\u001b[32m   1392\u001b[39m     \u001b[38;5;66;03m# FileSystem dir_cache since this info was already asked for in\u001b[39;00m\n\u001b[32m   1393\u001b[39m     \u001b[38;5;66;03m# _collect_dataset_info\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1394\u001b[39m     checksum.append(\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchecksum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1395\u001b[39m dataset_info[\u001b[33m\"\u001b[39m\u001b[33mchecksum\u001b[39m\u001b[33m\"\u001b[39m] = tokenize(checksum)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/fsspec/asyn.py:118\u001b[39m, in \u001b[36msync_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28mself\u001b[39m = obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/fsspec/asyn.py:103\u001b[39m, in \u001b[36msync\u001b[39m\u001b[34m(loop, func, timeout, *args, **kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/fsspec/asyn.py:56\u001b[39m, in \u001b[36m_runner\u001b[39m\u001b[34m(event, coro, result, timeout)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     result[\u001b[32m0\u001b[39m] = \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/s3fs/core.py:1517\u001b[39m, in \u001b[36mS3FileSystem._checksum\u001b[39m\u001b[34m(self, path, refresh)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[33;03mUnique value for current version of file\u001b[39;00m\n\u001b[32m   1503\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1514\u001b[39m \n\u001b[32m   1515\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1517\u001b[39m info = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._info(path, refresh=refresh)\n\u001b[32m   1519\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m info[\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m] != \u001b[33m\"\u001b[39m\u001b[33mdirectory\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/s3fs/core.py:1428\u001b[39m, in \u001b[36mS3FileSystem._info\u001b[39m\u001b[34m(self, path, bucket, key, refresh, version_id)\u001b[39m\n\u001b[32m   1427\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m refresh:\n\u001b[32m-> \u001b[39m\u001b[32m1428\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ls_from_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/fsspec/spec.py:379\u001b[39m, in \u001b[36mAbstractFileSystem._ls_from_cache\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) == \u001b[32m0\u001b[39m:\n\u001b[32m    378\u001b[39m     \u001b[38;5;66;03m# parent dir was listed but did not contain this file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(path)\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m files\n",
      "\u001b[31mFileNotFoundError\u001b[39m: weather/main/weather.parquet/year=2025/month=5/day=8/hour=6/dd1741ec35434825a62561e9625ed3e8-0.parquet",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mdask\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataframe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mdd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df2 = \u001b[43mdd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_all_partition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpyarrow\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m  \n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/dask/backends.py:151\u001b[39m, in \u001b[36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: An error occurred while calling the read_parquet method registered to the pandas backend.\nOriginal Message: weather/main/weather.parquet/year=2025/month=5/day=8/hour=6/dd1741ec35434825a62561e9625ed3e8-0.parquet"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "df2 = dd.read_parquet(\n",
    "    path=path_all_partition,\n",
    "    storage_options=storage_options,\n",
    "    dtype_backend='pyarrow'\n",
    ")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
